{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import json_lines\n",
    "import logging\n",
    "import collections\n",
    "import json\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import argparse\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadExample(object):\n",
    "    \"\"\"\n",
    "    A single training/test example for the Squad dataset.\n",
    "    For examples without an answer, the start and end position are -1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 qas_id,\n",
    "                 question_text,\n",
    "                 doc_tokens,\n",
    "                 orig_answer_text=None,\n",
    "                 start_position=None,\n",
    "                 end_position=None):\n",
    "        self.qas_id = qas_id\n",
    "        self.question_text = question_text\n",
    "        self.doc_tokens = doc_tokens\n",
    "        self.orig_answer_text = orig_answer_text\n",
    "        self.start_position = start_position\n",
    "        self.end_position = end_position\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        s += \"qas_id: %s\" % (self.qas_id)\n",
    "        s += \", question_text: %s\" % (self.question_text)\n",
    "        s += \", doc_tokens: [%s]\" % (\" \".join(self.doc_tokens))\n",
    "        if self.start_position:\n",
    "            s += \", start_position: %d\" % (self.start_position)\n",
    "        if self.end_position:\n",
    "            s += \", end_position: %d\" % (self.end_position)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_squad_examples(input_file, debug=False):\n",
    "    # Read data\n",
    "    unproc_data = []\n",
    "    with gzip.open(input_file, 'rt', encoding='utf-8') as f:  # opening file in binary(rb) mode\n",
    "        for item in json_lines.reader(f):\n",
    "            # print(item) #or use print(item['X']) for printing specific data\n",
    "            unproc_data.append(item)\n",
    "\n",
    "    # Delete header\n",
    "    unproc_data = unproc_data[1:]\n",
    "    if debug:\n",
    "        unproc_data = unproc_data[:100]\n",
    "\n",
    "    ###################### Make Examples ######################\n",
    "    examples = []\n",
    "    for item in unproc_data:\n",
    "        # 1. Get Context\n",
    "        doc_tokens = []\n",
    "        for token in item['context_tokens']:\n",
    "            # BERT has only [SEP] in it's word piece vocabulary. because we keps all separators char length 5\n",
    "            # we can replace all of them with [SEP] without modifying the offset\n",
    "            if token[0] in ['[TLE]', '[PAR]', '[DOC]']:\n",
    "                token[0] = '[SEP]'\n",
    "            doc_tokens.append(token[0])\n",
    "\n",
    "        # 2. qas\n",
    "        for qa in item['qas']:\n",
    "            qas_id = qa['qid']\n",
    "            question_text = qa['question']\n",
    "\n",
    "            answer_lst = []  # Check for duplicate question\n",
    "            for answer in qa['detected_answers']:\n",
    "                orig_answer_text = answer['text']\n",
    "                # We could find so many duplicate \"Detected Answer\"...It needs to be erased\n",
    "                if orig_answer_text in answer_lst:\n",
    "                    continue\n",
    "                else:\n",
    "                    answer_lst.append(orig_answer_text)\n",
    "\n",
    "                # Only take the first span\n",
    "                start_position = answer['token_spans'][0][0]\n",
    "                end_position = answer['token_spans'][0][1]\n",
    "\n",
    "                example = SquadExample(\n",
    "                    qas_id=qas_id,\n",
    "                    question_text=question_text,\n",
    "                    doc_tokens=doc_tokens,\n",
    "                    orig_answer_text=orig_answer_text,\n",
    "                    start_position=start_position,\n",
    "                    end_position=end_position)\n",
    "                examples.append(example)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_squad_examples(\"data/train/SQuAD.jsonl.gz\", debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robustqa",
   "language": "python",
   "name": "robustqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
