{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import g\n",
    "def read_squad_examples(input_file, debug=False):\n",
    "    # Read data\n",
    "    unproc_data = []\n",
    "    with gzip.open(input_file, 'rt', encoding='utf-8') as f:  # opening file in binary(rb) mode\n",
    "        for item in json_lines.reader(f):\n",
    "            # print(item) #or use print(item['X']) for printing specific data\n",
    "            unproc_data.append(item)\n",
    "\n",
    "    # Delete header\n",
    "    unproc_data = unproc_data[1:]\n",
    "    if debug:\n",
    "        unproc_data = unproc_data[:100]\n",
    "\n",
    "    ###################### Make Examples ######################\n",
    "    examples = []\n",
    "    for item in unproc_data:\n",
    "        # 1. Get Context\n",
    "        doc_tokens = []\n",
    "        for token in item['context_tokens']:\n",
    "            # BERT has only [SEP] in it's word piece vocabulary. because we keps all separators char length 5\n",
    "            # we can replace all of them with [SEP] without modifying the offset\n",
    "            if token[0] in ['[TLE]', '[PAR]', '[DOC]']:\n",
    "                token[0] = '[SEP]'\n",
    "            doc_tokens.append(token[0])\n",
    "\n",
    "        # 2. qas\n",
    "        for qa in item['qas']:\n",
    "            qas_id = qa['qid']\n",
    "            question_text = qa['question']\n",
    "\n",
    "            answer_lst = []  # Check for duplicate question\n",
    "            for answer in qa['detected_answers']:\n",
    "                orig_answer_text = answer['text']\n",
    "                # We could find so many duplicate \"Detected Answer\"...It needs to be erased\n",
    "                if orig_answer_text in answer_lst:\n",
    "                    continue\n",
    "                else:\n",
    "                    answer_lst.append(orig_answer_text)\n",
    "\n",
    "                # Only take the first span\n",
    "                start_position = answer['token_spans'][0][0]\n",
    "                end_position = answer['token_spans'][0][1]\n",
    "\n",
    "                example = SquadExample(\n",
    "                    qas_id=qas_id,\n",
    "                    question_text=question_text,\n",
    "                    doc_tokens=doc_tokens,\n",
    "                    orig_answer_text=orig_answer_text,\n",
    "                    start_position=start_position,\n",
    "                    end_position=end_position)\n",
    "                examples.append(example)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gzip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-220-9045578ef30b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mread_squad_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datasets/race\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-218-b01b78e49c9b>\u001b[0m in \u001b[0;36mread_squad_examples\u001b[0;34m(input_file, debug)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Read data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0munproc_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# opening file in binary(rb) mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_lines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;31m# print(item) #or use print(item['X']) for printing specific data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gzip' is not defined"
     ]
    }
   ],
   "source": [
    "read_squad_examples(\"datasets/race\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robustqa",
   "language": "python",
   "name": "robustqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
